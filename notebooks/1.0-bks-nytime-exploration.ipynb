{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYTimes COVID-19 Dataset\n",
    "---\n",
    "NYTimes provides a dataset containing cases, deaths, state, fips (county code), and dates for the cases as the pandemic evolves over time. This information can be used as presented in raw data for the number of cases in a location over time but it may be handy to create features from this data to performing some time series forecasting of cases or deaths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolving influenza data from 2018 - 2019\n",
    "\n",
    "* The flu data from https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html can provide some information as to how COVID-19 may spread during the winter season. The Spanish Flu is considered to be more like the COVID-19 in mortality and contagiousness as indicated by https://www.informationisbeautiful.net/visualizations/the-microbescope-infectious-diseases-in-context/. However, Spanish Flu data is scarce and so the flu data will have to suffice as a guideline.\n",
    "* As the data overall is incomplete and projections are only made for a few months, the best I can do is normalize the data and then average for each state and attempt to use that as a guideline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   REGION    2891 non-null   object        \n",
      " 1   WEEK      2891 non-null   datetime64[ns]\n",
      " 2   ILITOTAL  2891 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 67.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>ILITOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>5145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>1963.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       REGION       WEEK  ILITOTAL\n",
       "0     Alabama 2018-01-20    5145.0\n",
       "1      Alaska 2018-01-20     199.0\n",
       "2     Arizona 2018-01-20    1056.0\n",
       "3    Arkansas 2018-01-20     419.0\n",
       "4  California 2018-01-20    1963.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #Dataframes for data\n",
    "flu_df = pd.read_csv(\"../data/raw/ILINet.csv\")\n",
    "flu_df['ILITOTAL'] = flu_df['ILITOTAL'].astype(float)\n",
    "flu_df['WEEK'] = pd.to_datetime(flu_df['WEEK'], format='%m/%d/%Y')\n",
    "flu_df.info()\n",
    "flu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>ILITOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>0.973891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>0.318359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>0.654459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>0.800393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       REGION       WEEK  ILITOTAL\n",
       "0     Alabama 2018-01-20  0.973891\n",
       "1      Alaska 2018-01-20  0.318359\n",
       "2     Arizona 2018-01-20  1.000000\n",
       "3    Arkansas 2018-01-20  0.654459\n",
       "4  California 2018-01-20  0.800393"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = flu_df.REGION.unique()\n",
    "\n",
    "for state in states:\n",
    "    sub_df = flu_df[flu_df[\"REGION\"] == state].drop(['REGION','WEEK'],1)\n",
    "    sub_df = ( sub_df - sub_df.min() ) / ( sub_df.max() - sub_df.min() )\n",
    "    flu_df.update(sub_df)\n",
    "    \n",
    "flu_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now that the ILITOTAL's have been normalized by state, the weeks will be averaged to make the data more appliable to the whole dataset as, for example, Florida's data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dates  ILITOTAL\n",
      "0  2018-01-20  0.582319\n",
      "1  2018-01-27  0.694342\n",
      "2  2018-02-03  0.763799\n",
      "3  2018-02-10  0.772556\n",
      "4  2018-02-17  0.683107\n",
      "5  2018-02-24  0.494634\n",
      "6  2018-03-03  0.375379\n",
      "7  2018-03-10  0.299736\n",
      "8  2018-03-17  0.252403\n",
      "9  2018-03-24  0.229393\n",
      "10 2018-03-31  0.192248\n",
      "11 2018-04-07  0.175035\n",
      "12 2018-04-14  0.146973\n",
      "13 2018-04-21  0.122915\n",
      "14 2018-04-28  0.115158\n",
      "15 2018-05-05  0.095298\n",
      "16 2018-05-12  0.077972\n",
      "17 2018-05-19  0.066162\n",
      "18 2018-05-26  0.061652\n",
      "19 2018-06-02  0.048488\n",
      "20 2018-06-09  0.041093\n",
      "21 2018-06-16  0.025758\n",
      "22 2018-06-23  0.029080\n",
      "23 2018-06-30  0.026398\n",
      "24 2018-07-07  0.021421\n",
      "25 2018-07-14  0.023417\n",
      "26 2018-07-21  0.016825\n",
      "27 2018-07-28  0.015261\n",
      "28 2018-08-04  0.013522\n",
      "29 2018-08-11  0.019205\n",
      "30 2018-08-18  0.021029\n",
      "31 2018-08-25  0.029590\n",
      "32 2018-09-01  0.039981\n",
      "33 2018-09-08  0.051239\n",
      "34 2018-09-15  0.058043\n",
      "35 2018-09-22  0.061276\n",
      "36 2018-09-29  0.067154\n",
      "37 2018-10-06  0.134738\n",
      "38 2018-10-13  0.144780\n",
      "39 2018-10-20  0.148313\n",
      "40 2018-10-27  0.165366\n",
      "41 2018-11-03  0.180854\n",
      "42 2018-11-10  0.182914\n",
      "43 2018-11-17  0.185039\n",
      "44 2018-11-24  0.175459\n",
      "45 2018-12-01  0.222453\n",
      "46 2018-12-08  0.222109\n",
      "47 2018-12-15  0.262855\n",
      "48 2018-12-22  0.300561\n",
      "49 2018-12-29  0.346615\n",
      "50 2019-01-05  0.348984\n",
      "51 2019-01-12  0.378738\n",
      "52 2019-01-19  0.415211\n",
      "53 2019-01-26  0.465776\n",
      "54 2019-02-02  0.535670\n",
      "55 2019-02-09  0.637074\n",
      "56 2019-02-16  0.651741\n",
      "57 2019-02-23  0.649173\n",
      "58 2019-02-28  0.605066\n"
     ]
    }
   ],
   "source": [
    "weeks = flu_df.WEEK.unique()\n",
    "temp_dict = {}\n",
    "\n",
    "for week in weeks:\n",
    "    sub_df = flu_df[flu_df['WEEK'] == week].drop(['REGION','WEEK'],1)\n",
    "    temp_dict[week] = sub_df.mean()\n",
    "    \n",
    "ili_norm = pd.DataFrame.from_dict(temp_dict,orient='index')\n",
    "ili_norm.reset_index(inplace=True)\n",
    "ili_norm = ili_norm.rename(columns = {'index':'dates'})\n",
    "print(ili_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The normalized values provide weekly data but the cases in the NYTimes dataset are daily. Linear Interpolation will be used here to fill in the missing weekly information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 405 entries, 0 to 404\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   dates     405 non-null    datetime64[ns]\n",
      " 1   ILITOTAL  405 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 6.5 KB\n"
     ]
    }
   ],
   "source": [
    "ili_norm.index = ili_norm['dates']\n",
    "del ili_norm['dates']\n",
    "ili_norm = ili_norm.resample('D').mean()\n",
    "ili_norm['ILITOTAL'] = ili_norm['ILITOTAL'].interpolate()\n",
    "ili_norm.reset_index(inplace=True)\n",
    "ili_norm.info()\n",
    "ili_norm['dates'] = ili_norm['dates'] + pd.Timedelta(days=731) #Move it over 2 years for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>ILITOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>0.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>0.631530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>0.622709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>2021-02-27</td>\n",
       "      <td>0.613888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>0.605066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dates  ILITOTAL\n",
       "400 2021-02-24  0.640351\n",
       "401 2021-02-25  0.631530\n",
       "402 2021-02-26  0.622709\n",
       "403 2021-02-27  0.613888\n",
       "404 2021-02-28  0.605066"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ili_norm.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The overall trend appears to be what we are looking for. I'll read in the data from NYTimes dataset and try to fit the already existing data to the normalized values presented in ili_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYTimes Data Preparation\n",
    "Reading in the NYTimes data and cleaning it up to match the flu data that was generated from above to perform time series forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 681089 entries, 0 to 703073\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   date    681089 non-null  object \n",
      " 1   county  681089 non-null  object \n",
      " 2   state   681089 non-null  object \n",
      " 3   fips    681089 non-null  float64\n",
      " 4   cases   681089 non-null  int64  \n",
      " 5   deaths  681089 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 36.4+ MB\n",
      "(681089, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Cook</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17031.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     county       state     fips  cases  deaths\n",
       "0  2020-01-21  Snohomish  Washington  53061.0      1       0\n",
       "1  2020-01-22  Snohomish  Washington  53061.0      1       0\n",
       "2  2020-01-23  Snohomish  Washington  53061.0      1       0\n",
       "3  2020-01-24       Cook    Illinois  17031.0      1       0\n",
       "4  2020-01-24  Snohomish  Washington  53061.0      1       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/covid-19-data/us-counties.csv')\n",
    "df = df[df['fips'] < 60000]\n",
    "df.info()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here I need to convert the date column to datetime and drop the county/state/deaths column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 681089 entries, 0 to 703073\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype         \n",
      "---  ------  --------------   -----         \n",
      " 0   date    681089 non-null  datetime64[ns]\n",
      " 1   fips    681089 non-null  float64       \n",
      " 2   cases   681089 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 20.8 MB\n",
      "(681089, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>17031.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     fips  cases\n",
       "0 2020-01-21  53061.0      1\n",
       "1 2020-01-22  53061.0      1\n",
       "2 2020-01-23  53061.0      1\n",
       "3 2020-01-24  17031.0      1\n",
       "4 2020-01-24  53061.0      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['county','state','deaths'],1)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "#df.date = df.date.dt.isocalendar().week\n",
    "df.info()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The dates can be utilized as is with the already interpolated ili_norm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2020-01-21\n",
      "1     2020-01-22\n",
      "2     2020-01-23\n",
      "3     2020-01-24\n",
      "4     2020-01-25\n",
      "         ...    \n",
      "400   2021-02-24\n",
      "401   2021-02-25\n",
      "402   2021-02-26\n",
      "403   2021-02-27\n",
      "404   2021-02-28\n",
      "Name: dates, Length: 405, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(ili_norm['dates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fortunately it looks like prior cleaning of the flu data had left the starting week to January 20th, encompassing the NYTimes data already. This can be used to match the data for the time series forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacency Data\n",
    "Prior processing allowed for the generation of the list of counties represented in fips with their adjacent county also represented in fips. Further processing then converted this list to a sum of cases in a county and adjacent counties per county per date. The explanation of this csv file being generated is present in the scripts directory. Reading in the adjacency data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1095005 entries, 0 to 1095004\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count    Dtype  \n",
      "---  ------     --------------    -----  \n",
      " 0   fips       1095005 non-null  float64\n",
      " 1   date       1095005 non-null  object \n",
      " 2   adj_cases  1095005 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 25.1+ MB\n",
      "(1095005, 3)\n",
      "            fips        date  adj_cases\n",
      "0        53061.0  2020-01-21         39\n",
      "1        53061.0  2020-01-22          4\n",
      "2        53061.0  2020-01-23          1\n",
      "3        53061.0  2020-01-24          2\n",
      "4        53061.0  2020-01-25          0\n",
      "...          ...         ...        ...\n",
      "1095000   2230.0  2021-02-24         43\n",
      "1095001   2230.0  2021-02-25         43\n",
      "1095002   2230.0  2021-02-26         43\n",
      "1095003   2230.0  2021-02-27         43\n",
      "1095004   2230.0  2021-02-28         42\n",
      "\n",
      "[1095005 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "adj_df = pd.read_csv(\"../data/processed/adj_sum.csv\")\n",
    "adj_df = adj_df.drop('Unnamed: 0', 1)\n",
    "adj_df.info()\n",
    "print(adj_df.shape)\n",
    "print(adj_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The simplest use of the adjacency data is to make a feature that represents the sum of the number of cases surrounding each county. This should help model possible outside influence for case development in each county\n",
    "* As each county will need its own processing, it will be a messy set of for loops that generated separate dataframes and adjacency data that is then used in the time series forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor #Decision Tree Regressor for modeling\n",
    "import datetime as dt #To Ordinal for training\n",
    "\n",
    "failed_fips = []\n",
    "model_dt = DecisionTreeRegressor(random_state=0)\n",
    "exp_df = pd.DataFrame(columns=['date','fips','cases'])\n",
    "\n",
    "for fips in df.fips.unique():\n",
    "    try:\n",
    "        #Piecing the separate dataframes together\n",
    "        #adj_cases\n",
    "        sub_df = df[df['fips'] == fips]\n",
    "        temp = adj_df[adj_df['fips'] == fips]\n",
    "        temp = temp.loc[temp['date'].isin(sub_df['date'].astype(str).unique()),'adj_cases'].tolist()\n",
    "        sub_df.insert(3,'adj_cases',temp,True)\n",
    "        sub_df = sub_df.dropna()\n",
    "\n",
    "        #ili_norm\n",
    "        temp = ili_norm.loc[ili_norm['dates'].isin(sub_df['date'].astype(str).unique()),'ILITOTAL'].tolist()\n",
    "        sub_df.insert(3,'ili_norm',temp,True)\n",
    "    \n",
    "   \n",
    "        #Modeling\n",
    "        y = sub_df['cases']\n",
    "        x = sub_df.drop(['cases','fips'],1)\n",
    "        x['year'] = x['date'].dt.year\n",
    "        x['month'] = x['date'].dt.month\n",
    "        x['day'] = x['date'].dt.day\n",
    "        x = x.drop(['date'], 1)\n",
    "        x['adj_cases'] = ( x['adj_cases'] - x['adj_cases'].min() ) / ( x['adj_cases'].max() - x['adj_cases'].min() )\n",
    "        model_dt.fit(x, y)\n",
    "\n",
    "        #Predicting\n",
    "        predict_df = pd.date_range(max(df['date']) + pd.Timedelta(days=1), max(df['date']) + pd.Timedelta(days=115)).to_frame(index=False,name='date')\n",
    "        temp = adj_df[adj_df['fips'] == fips].copy()\n",
    "        temp['adj_cases'] = ( temp['adj_cases'] - temp['adj_cases'].min() ) / ( temp['adj_cases'].max() - temp['adj_cases'].min() )\n",
    "\n",
    "        temp = temp.loc[temp['date'].isin(predict_df['date'].astype(str).unique()),'adj_cases'].tolist()\n",
    "        predict_df.insert(1,'adj_cases',temp,True)\n",
    "        temp = ili_norm.loc[ili_norm['dates'].isin(predict_df['date'].astype(str).unique()),'ILITOTAL'].tolist()\n",
    "        predict_df.insert(2,'ili_norm',temp,True)\n",
    "        predict_df['year'] = predict_df['date'].dt.year\n",
    "        predict_df['month'] = predict_df['date'].dt.month\n",
    "        predict_df['day'] = predict_df['date'].dt.day\n",
    "        predict_df = predict_df.drop(['date'], 1)\n",
    "        predicted = model_dt.predict(predict_df)\n",
    "        predicted = predicted + y.tail(1).iloc[0]\n",
    "        \n",
    "        #Setup for export\n",
    "        app_df = pd.DataFrame(predicted).join(predict_df).rename(columns = {0:'cases'})\n",
    "        app_df['date'] = pd.to_datetime(predict_df[['year', 'month', 'day']])\n",
    "        app_df = app_df.drop(['year','month','day'],1)\n",
    "        app_df['fips'] = fips\n",
    "        app_df = app_df[['date', 'fips', 'cases']]\n",
    "        exp_df = exp_df.append(df[df['fips'] == fips])\n",
    "        exp_df = exp_df.append(app_df)\n",
    "    except:\n",
    "        failed_fips.append(fips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "* With the csv generated for predicted cases I'll simply output to a csv for reuse of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df.to_csv('../data/processed/dtr_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
